---
title: 'COSORE: a community database for continuous soil respiration and other chamber
  fluxes'
output:
  html_document: default
  word_document: default
date: "`r format(Sys.time(), '%d %B %Y')`"
---

This document is the core of the planned ESSD manuscript: summarizing the database, giving stats, describing functions, etc. Most of the introductory text with citations will be in the Google Doc.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(cosore)
library(dplyr)
library(lubridate)
library(readr)
library(tidyr)
library(covr)

db <- csr_database() %>% mutate(CTB = ymd(CSR_TIME_BEGIN), CTE = ymd(CSR_TIME_END))
db_records <- round(sum(db$CSR_RECORDS, na.rm = TRUE) / 1e6, 2)
db_years <- max(year(db$CTE), na.rm = TRUE) - min(year(db$CTB), na.rm = TRUE) + 1
db_fields <- read_csv(system.file("extdata", "CSR_COLUMN_UNITS.csv", package = "cosore"), 
                      col_types  = "cccccl", comment = "#")
db_vers <- packageVersion("cosore")
```

```{r authors}
csr_table("contributors") %>% 
  left_join(select(db, CSR_DATASET, CSR_RECORDS), by = "CSR_DATASET") %>% 
  filter(CSR_RECORDS > 0) %>%  # only authors who contribute data
  group_by(CSR_DATASET) %>% 
  mutate(`Author?` = "No", 
         `Institution and address` = "") %>% 
  select(CSR_DATASET, CSR_FAMILY_NAME, CSR_FIRST_NAME, `Author?`,
         CSR_EMAIL, CSR_ORCID, `Institution and address`) %T>% 
  write_csv("authors_no.csv", na = "") %>% 
  group_by(CSR_DATASET) %>% 
  filter(CSR_FAMILY_NAME == first(CSR_FAMILY_NAME)) %>% 
  pull(CSR_EMAIL) %>% 
  unique() %>% 
  write_lines("authors_contact.csv")
```

## The COSORE database

COSORE is designed to be a relatively lightweight database: as simple as possible, but not simpler. 
It is targeted at continuous soil respiration flux data--i.e., those measured by automated systems on a e.g. half hourly basis--but its design accommodates survey-style R~S~ fluxes, methane fluxes, and chamber measurements of net ecosystem exchange as well, paralleling the recent SIdB database (TODO). 
Its development started in April 2019, and as of this writing (`r Sys.Date()`) the COSORE version number is `r db_vers`. 
The database currently has `r nrow(db)` contributed datasets with a total of `r db_records` million flux observations across `r db_years` years and five continents (Table X, Figure X).

### Overall database structure

The database is structured as a collection of independent contributed _datasets_, all of which have been standardized to a common structure, units, etc. 
Each dataset is given a reference name that links its constituent tables, provides a point of reference in reports, and is used when calling the R package accessor functions (see below).

### Individual dataset structure

Each constituent dataset normally has a series of separate data tables that are linked by keys.
These tables include:

* `description` (**Table 2**) describing site and dataset characteristics;
* `contributors` (**Table 3**) listing individuals who contributed to the measurement, analysis,
curation, and/or submission of the dataset; 
* `ports` (**Table 4**) which gives the different _ports_ (generally equivalent to separate measurement chambers) in use, and what each is measuring: flux, species, and treatment, as well as characteristics of the measurement collar;
* `data` (**Table 5**), the central table of the dataset, which records flux observations;
* `ancillary` (**Table 6**) summarizing site-level ancillary measurements;
* `columns` (**Table 7**), mapping raw data columns to standard COSORE columns, providing a record for reproducibility; and
* `diagnostics` (**Table 8**), which provides statistics on the data import process: errors, columns and rows dropped, etc.

The common key linking these dataset tables is the `CSR_DATASET` field, which records the unique name assigned to the dataset. In addition, a `CSR_PORT` key field links the `ports` and `data` tables. These links make it straightforward to extract datasets that have measured particular fluxes in
certain ecosystem types, or isolate only non-treatment (control) chamber fluxes, for example.

### Database versioning and archiving

COSORE uses semantic versioning (https://semver.org/), meaning that its version numbers
generally follow an "x.y.z" format, where _x_ is the major version number (changing only when there are major changes to the database structure and/or functioning); _y_ is the minor version number (typically changing with significant data updates); and _z_ the patch number (bug fixes, documentation upgrades, or other changes that are completely backwards compatible).
Following each official (major) release a DOI will be issued and the data archived by Zenodo (https://zenodo.org/).
All changes to the data or codebase are immediately available through the GitHub repository, but only official releases will be issued a DOI.

### Database license

The database license is CC-BY-4 (https://creativecommons.org/licenses/by/4.0/); see the "LICENSE` file in the repository.
This is identical to that used by e.g. Ameriflux and FLUXNET Tier 1. 
In general, this license provides that users may copy and redistribute the database and R package code in any medium or format, adapting and building upon them for any scientific or commercial purpose, as long as appropriate credit is given.
We request that users cite this database definition paper, and strongly encourage them to (i) cite all constituent dataset primary publications, and (ii) involve data contributors as co-authors when possible.

### Citing COSORE

Papers or other research products using COSORE should cite this publication. 
In addition, users should also reference the specific version of the dataset they used (e.g. `r db_vers`), access date, and ideally the specific Git commit number. 
This provides full reproducibility of any analyses.
As noted above, we encourage data users to cite the primary publication for each dataset
they use in analyses as well.

## Accessing COSORE data

### Downloading a release

COSORE data releases are currently available via the GitHub "Releases" page at https://github.com/bpbond/cosore/releases, although we anticipate that institutional repositories such as ESS-DIVE may host releases at some point in the future.
Downloads via this page are flat-file CSV (comma-separated value), and readable by any modern computing system. 
Missing values are encoded by a blank (i.e. two successive commas in the CSV format).
A release download is fully self-contained, with full data and documentation, links to this publication, a file manifest, etc.

### Using the R package

An alternative way to access COSORE data is to install and use the `cosore` R package.
This provides a robust framework, including dedicated access functions, dataset and database report generation, and QA/QC (see below).

```{r dbsize, include=FALSE, cache=TRUE}
db_memsize <- sum(sapply(db$CSR_DATASET, function(x) object.size(csr_dataset(x)$data))) / 1e6
db_disksize <- system2("git", 
                       args = c("count-objects", "-vH"), 
                       stdout = TRUE)
db_disksize <- db_disksize[grepl("size:",db_disksize)]
db_disksize <- gsub("size: ", "", db_disksize)
```

Because currently the flux data are included in the repository itself, the latter is quite large (compared to most Git repositories) to download, ~`r db_disksize`. (Note that the data are stored in R's compressed `RDS` file format; when loaded into memory, the entire database is significantly larger, ~`r round(db_memsize, 0)` MiB.) It thus cannot easily be hosted on CRAN (the Comprehensive R Archive Network), the canonical source for R packages. Installing directly from GitHub is however straightforward using the `devtools` or `remotes` packages:

```
devtools::install_github("bpbond/cosore")
library(cosore)
```

A specific release number may also be installed:

```
devtools::install_github("bpbond/cosore@v0.4")
```

Three primary user-facing functions are available:

* `csr_database()` summarizes the entire database in a single convenient data frame, with one row per dataset, and is intended as a high-level overview. It returns a selection of variables summarized in **Tables 2-8** below, including dataset name, longitude, latitude, elevation, IGBP code, number of records, dates, and variables measured.
* `csr_dataset()` returns a single dataset: an R list structure, each element of which is a table (`description`, `contributors`, etc., as described above). 
* `csr_table()` collects, into a single data frame, one of the tables (`description`, `contributors`, etc., as described above) of the database, for any or all datasets.

Two additional reporting functions may also be useful to COSORE users:

* `csr_report_database()` generates an HTML report on the entire database: number of datasets, locations, number of observations, distribution of flux values, etc.
* `csr_report_dataset()` generates an HTML report on a single dataset, including tabular and graphical summaries of location, flux data, diagnostics, etc.

Finally, a number of functions are targeted at developers, and include functionality to ingest contributed data, standardize data, and prepare a new release. See the package documentation for more details on these.

#### Documentation and vignettes

The primary documentation for the COSORE database is this paper.
Both the flat-file releases and `cosore` R package include extensive documentation, including an in-depth vignette included both in the package and online (LINK TODO).
The R package includes documentation available via R's standard help system.

#### Testing and quality assurance

When contributed data are imported into COSORE, the package code performs a number of quality assurance checks. These include:

* Timestamp errors, for example illegal dates and times for the specified time zone
* Bad email addresses or ORCID identifiers
* Records with no flux value
* Records for which the analyzer recorded an error condition
* Extremely low or high (<-10 and >50 µmol m^-2^ s^-1^ respectively) flux rates
* Extremely low or high temperature values

```{r errors, cache=TRUE}
# Calculate what percent of observations are removed across all datasets
csr_table("diagnostics", quiet = TRUE) %>% 
  group_by(CSR_DATASET, CSR_RECORDS) %>% 
  summarise(removed = CSR_RECORDS_REMOVED_NA + CSR_RECORDS_REMOVED_ERR +
                          CSR_RECORDS_REMOVED_TOOLOW + CSR_RECORDS_REMOVED_TOOHIGH +
                          CSR_RECORDS_REMOVED_TIMESTAMP) %>% 
  ungroup() %>% 
  mutate(removed_pct = removed / (removed + CSR_RECORDS) * 100) %>% 
  pull(removed_pct) -> errs
```

Any errors flagged or records removed during this process are summarized in the _diagnostics_ table that is part of each dataset (**Table 7** below). Across all contributed datasets, a median of `r round(median(errs), 1)`% of raw observations were removed for one of these reasons.

```{r coverage, cache=TRUE}
# We exclude parse-others.R from the coverage calculation, because it's all
# temporary code for handling specific raw datasets, and will eventually go away
package_coverage(line_exclusions = list("R/parse-others.R")) %>% 
  percent_coverage() ->
  csr_cov
```

The `cosore` R package also has a wide variety of unit tests (CITATION TODO) that test code functionality, typically via assertions about function behavior, but also by verifying behavior of those functions when importing test datasets (of different formats and with a variety of errors, for example). In total these tests cover `r round(csr_cov, 1)`% of the codebase.

## The `cosore` repository

### Reporting issues

Like any dataset or piece of software, COSORE undoubtedly has problems: incomplete or incorrect data, faulty logic, documentation gaps. 
We use the `cosore` GitHub issue tracker (https://github.com/bpbond/cosore/issues) to track and categorize user improvement suggestions, problems or errors with the R package code or database data, requests for new variables or functionality, and/or asking questions on any other aspect of COSORE.
The COSORE team welcomes questions, contributions, and suggestions; all issues and discussion are subject to a code of conduct (see the "CODE_OF_CONDUCT.md" file in the repository).

### Contributing data

The COSORE team welcomes data contributions of chamber flux data. We prioritize continuously-measured
(i.e. from automated systems) soil respiration datasets, but the database structure also accommodates
long-term survey (discontinuous) data; measurements of methane, net ecosystem exchange, and
heterotrophic respiration fluxes.

It is important to note that COSORE itself is not designed to be, and should not be treated as, a permanent data repository. 
It is an open community database, but not an institutionally-backed repository like Figshare (https://figshare.com), DataONE (https://www.dataone.org), ESS-DIVE (https://ess-dive.lbl.gov), ORNL-DAAC (https://daac.ornl.gov), etc. 
We recommend that contributors deposit data in one of these first, and providing its Digital Object Identifier (DOI) in the COSORE dataset metadata.

# Tables

**Table 1.** Summary of COSORE v. `r db_vers` datasets with deposited data, by International Geosphere-Biosphere Programme land cover classification (CITATION TODO). Columns include number of datasets, total number of records (flux observations), and dates of first and last records.

```{r table_igbp}
smrise <- function(x) {
  x %>% 
    summarise(Datasets = n(),
              Records = format(sum(CSR_RECORDS, na.rm = TRUE), big.mark = ","),
              `First record` = min(CTB, na.rm = TRUE),
              `Last record` = max(CTE, na.rm = TRUE)) 
}
db %>% 
  filter(CSR_RECORDS > 0) %>% 
  select(`IGBP class` = CSR_IGBP, CSR_RECORDS, CTB, CTE) %>% 
  group_by(`IGBP class`) %>% 
  smrise() %>% 
  bind_rows(bind_cols(tibble(`IGBP class` = "(Total)"), smrise(db))) %>% 
  knitr::kable(format = "markdown", align = c("l", "r", "r", "r", "r"))
```

**Table 2.** Individual datasets in COSORE have a number of sub-tables. The first of these is the _description_ table, the fields of which are summarized below. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_description}
options(knitr.kable.NA = "")
make_table <- function(db_fields, table) {
  db_fields %>% 
    rename(`Field name` = Field_name) %>% 
    filter(Table_name == table) %>%
    mutate(Required = if_else(Required, "*", "")) %>% 
    select(-Table_name) %>% 
    kableExtra::kable(format = "markdown")
}
make_table(db_fields, "description")
```

**Table 3.** Summary of COSORE's _contributors_ table, which provides information on the researchers who measured and contributed each dataset. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required. Note that although none of the columns in this table are marked as required, at least one contributor (with filled-in name and email) is required for each dataset.

```{r table_contributors}
make_table(db_fields, "contributors")
```

**Table 4.** Summary of COSORE's _ports_ table, which provides information on the various multiplexed chambers that are frequently connected to a single measurement analyzer. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_ports}
make_table(db_fields, "ports")
```

**Table 5.** Summary of COSORE's _data_ table, which holds the actual flux observations. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_data}
make_table(db_fields, "data")
```

**Table 6.** Summary of COSORE's _ancillary_ table, which holds ecosystem-level optional information, typically soil information, carbon fluxes, and climate normals. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required. Here the first two rows (Variable and Value) describe the actual columns in the table; subsequent rows give examples of "Variable" entries.

```{r table_ancillary}
db_fields %>% 
  #  filter(Field_name %in%  c("Variable", "Value")) %>% 
  make_table("ancillary")
```

**Table 7.** Summary of COSORE's _columns_ table, which maps raw dataset columns to standardized COSORE columns. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required. We expect that this table will be dropped at some point in the future when COSORE requires structurally compliant data submissions (i.e. contributors will be required to format their data to match COSORE structure before submission).

```{r table_columns}
make_table(db_fields, "columns")
```

**Table 8.** Summary of COSORE's _diagnostics_ table, which is populated automatically when parsing and importing non-COSORE data. Columns include field name, description, class (i.e. type of data), units, and whether or not the field is required.

```{r table_diagnostics}
make_table(db_fields, "diagnostics")
```

# Figures

**Figure 1.** Map of sites...
```{r worldmap}
# We would like a world map with COSORE submission coordinates

# First option: a satellite image with COSORE points overlayed, this uses Google Maps
library(ggmap)
register_google(key = "AIzaSyAtPMvxK1yaV-cnzuxkcgqrt6ZTeB_NPmQ") # API key for Google access

bbox <- make_bbox(lon = c(-170, 170), lat = c(-70,70), f = 0) # make a coordinate box 
map <- get_map(location = bbox, source = "google", maptype = "roadmap", zoom = 1) # load map from online

ggmap(map) + 
  geom_point(data = db, aes(x = CSR_LONGITUDE, y = CSR_LATITUDE, fill = "COSORE Submission Site"), 
             alpha = 0.6, color = "#FC4E07", size = 2, shape = 18) + 
  xlim(c(-160, 160)) + 
  ylim(c(-40,70)) +
  labs(x = "Longitude", y = "Latitude") +
  scale_fill_manual(name = "", values = c("COSORE Submission Site" = "#FC4E07")) +
  scale_shape_manual(values = 18) + theme(legend.position="bottom")

```

**Figure 2.** Waffle plot of annual COSORE Coverage by IGBP, where one square equals 1,000 datapoints
```{r flux-density}
library(waffle)
csr_table(table = 'data') %>% left_join(db) -> data_meta

data_meta %>% mutate(Date = date(CSR_TIMESTAMP_BEGIN), Month = month(CSR_TIMESTAMP_BEGIN), 
                     Year = year(CSR_TIMESTAMP_BEGIN)) %>% 
  group_by(Year, CSR_IGBP) %>%
  summarise(CSR_FLUX = mean(CSR_FLUX, na.rm = TRUE), Date = mean(Date), n = n()/1000) -> avg

# waffle plot no of records by IGBP
ggplot(avg, aes(fill = CSR_IGBP, values = n)) +
        geom_waffle(color = "white", size = .25, n_rows = 10, flip = TRUE) +
        facet_wrap(~Year, nrow = 2, strip.position = "bottom") +  coord_equal() +
     labs(title = "Annual COSORE Coverage by IGBP",
        subtitle = "1 block = 1,000 data points",
        x = "Year",
        y = "Count") +
     theme_minimal() +
     theme(panel.grid = element_blank()) + 
  theme(axis.text.x = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks = element_blank())

#need to figure out what happens to datapoints under 1000

```

**Figure 3.** 
```{r lat-coverage}

data_meta %>% 
  select(CSR_DATASET, CSR_LATITUDE, CSR_TIMESTAMP_BEGIN, CSR_TIMESTAMP_END, CSR_IGBP) %>% 
  group_by(CSR_DATASET, CSR_IGBP) %>% 
  summarise(Latitude = mean(CSR_LATITUDE), Timestamp_begin = min(CSR_TIMESTAMP_BEGIN), Timestamp_end = max(CSR_TIMESTAMP_END), n = n()) -> test
                                                                                                             
ggplot(test, aes(color = CSR_IGBP)) + 
  geom_segment(aes(x = Timestamp_begin, y = Latitude, xend = Timestamp_end, yend = Latitude), 
               size = 2, alpha = 0.5) + 
  theme_minimal()
```

```{r sessionInfo}
# R session information
sessionInfo()
```
